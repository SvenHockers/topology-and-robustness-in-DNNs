{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mini CNN Image Classifier + Topology (Persistent Homology) Detector (Synthetic Images)\n",
        "\n",
        "This notebook tests the repo’s **topology-based detector** (`detector_type='topology_score'`) on an **image-like** setting using a **fully synthetic 2-class RGB dataset**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import importlib\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Project root\n",
        "CWD = os.getcwd()\n",
        "PROJECT_ROOT = os.path.abspath(os.path.join(CWD, \"..\")) if os.path.basename(CWD) == \"notebooks\" else os.path.abspath(CWD)\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "# Public pipeline API\n",
        "from src import api\n",
        "from src.utils import ExperimentConfig, set_seed\n",
        "\n",
        "from src.models import extract_features_batch\n",
        "from src.visualization import plot_roc_from_metrics, plot_confusion_matrix, plot_score_distributions_figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "\n",
        "# Dataset sizes\n",
        "N_TRAIN = 2000\n",
        "N_VAL = 500\n",
        "N_TEST = 500\n",
        "\n",
        "# Training\n",
        "EPOCHS = 8\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "\n",
        "# Attack (inputs in [0,1])\n",
        "ATTACK_TYPE = 'fgsm'  # 'fgsm' or 'pgd'\n",
        "EPSILON = 0.03\n",
        "PGD_STEPS = 10\n",
        "PGD_STEP_SIZE = 0.007\n",
        "\n",
        "# Topology detector settings\n",
        "TOPO_K = 40\n",
        "TOPO_MAXDIM = 1\n",
        "TOPO_PREPROCESS = 'pca'\n",
        "TOPO_PCA_DIM = 10\n",
        "TOPO_MIN_PERSISTENCE = 1e-6\n",
        "\n",
        "TOPO_PERCENTILE = 95.0\n",
        "TOPO_COV_SHRINKAGE = 1e-3\n",
        "\n",
        "# PH can be expensive; subsample scoring points\n",
        "MAX_POINTS_FOR_SCORING = 250\n",
        "\n",
        "print(f\"Attack: {ATTACK_TYPE}, eps={EPSILON}\")\n",
        "print(f\"Topology: k={TOPO_K}, maxdim={TOPO_MAXDIM}, preprocess={TOPO_PREPROCESS}({TOPO_PCA_DIM})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helpers\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def plot_samples(X: np.ndarray, y: np.ndarray, *, title: str, n_show: int = 8):\n",
        "    fig, axes = plt.subplots(1, n_show, figsize=(2.2 * n_show, 2.2))\n",
        "    for i in range(n_show):\n",
        "        img = X[i].transpose(1, 2, 0)\n",
        "        axes[i].imshow(np.clip(img, 0, 1))\n",
        "        axes[i].set_title(f\"y={int(y[i])}\")\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def compute_success_mask(model: nn.Module, X_clean: np.ndarray, X_adv: np.ndarray, y: np.ndarray, device: str):\n",
        "    pred_clean = api.predict(model, X_clean, device=device, return_probs=False)\n",
        "    pred_adv = api.predict(model, X_adv, device=device, return_probs=False)\n",
        "    y = np.asarray(y, dtype=int)\n",
        "    clean_correct = pred_clean == y\n",
        "    success = api.attack_success_mask(model, X_clean, X_adv, y, device=device)\n",
        "    return pred_clean, pred_adv, clean_correct, success\n",
        "\n",
        "\n",
        "def show_successful_attacks(\n",
        "    X_clean: np.ndarray,\n",
        "    X_adv: np.ndarray,\n",
        "    y_true: np.ndarray,\n",
        "    pred_clean: np.ndarray,\n",
        "    pred_adv: np.ndarray,\n",
        "    success_mask: np.ndarray,\n",
        "    *,\n",
        "    epsilon: float,\n",
        "    n_show: int = 6,\n",
        "    seed: int = 0,\n",
        "):\n",
        "    idx = np.where(success_mask)[0]\n",
        "    if len(idx) == 0:\n",
        "        print(\"No successful attacks to show.\")\n",
        "        return\n",
        "    rng = np.random.default_rng(seed)\n",
        "    chosen = rng.choice(idx, size=min(n_show, len(idx)), replace=False)\n",
        "\n",
        "    fig, axes = plt.subplots(len(chosen), 2, figsize=(7, 3 * len(chosen)))\n",
        "    if len(chosen) == 1:\n",
        "        axes = np.expand_dims(axes, axis=0)\n",
        "\n",
        "    for r, i in enumerate(chosen):\n",
        "        clean = np.clip(X_clean[i].transpose(1, 2, 0), 0, 1)\n",
        "        adv = np.clip(X_adv[i].transpose(1, 2, 0), 0, 1)\n",
        "        axes[r, 0].imshow(clean)\n",
        "        axes[r, 0].axis(\"off\")\n",
        "        axes[r, 0].set_title(f\"clean y={int(y_true[i])}, pred={int(pred_clean[i])}\")\n",
        "        axes[r, 1].imshow(adv)\n",
        "        axes[r, 1].axis(\"off\")\n",
        "        axes[r, 1].set_title(f\"adv pred={int(pred_adv[i])} (eps={epsilon})\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset (via public dataset registry)\n",
        "DATASET_NAME = \"synthetic_shapes_2class\"\n",
        "\n",
        "_data_cfg = ExperimentConfig(seed=SEED, device=DEVICE)\n",
        "_total = int(N_TRAIN + N_VAL + N_TEST)\n",
        "_data_cfg.data.n_samples = _total\n",
        "_data_cfg.data.train_ratio = float(N_TRAIN) / float(_total)\n",
        "_data_cfg.data.val_ratio = float(N_VAL) / float(_total)\n",
        "\n",
        "bundle = api.get_dataset(DATASET_NAME, _data_cfg)\n",
        "X_train, y_train = bundle.X_train, bundle.y_train\n",
        "X_val, y_val = bundle.X_val, bundle.y_val\n",
        "X_test, y_test = bundle.X_test, bundle.y_test\n",
        "\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"X_train: {X_train.shape} | y mean: {y_train.mean():.3f}\")\n",
        "print(f\"X_val:   {X_val.shape} | y mean: {y_val.mean():.3f}\")\n",
        "print(f\"X_test:  {X_test.shape} | y mean: {y_test.mean():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visual sanity-check\n",
        "plot_samples(X_train, y_train, title=f\"{DATASET_NAME}: first samples\", n_show=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model + experiment config (API)\n",
        "config = ExperimentConfig(seed=SEED, device=DEVICE)\n",
        "\n",
        "config.model.epochs = EPOCHS\n",
        "config.model.batch_size = BATCH_SIZE\n",
        "config.model.learning_rate = LR\n",
        "config.model.output_dim = 2\n",
        "\n",
        "config.attack.attack_type = ATTACK_TYPE\n",
        "config.attack.epsilon = EPSILON\n",
        "config.attack.num_steps = PGD_STEPS\n",
        "config.attack.step_size = PGD_STEP_SIZE\n",
        "config.attack.random_start = True\n",
        "\n",
        "config.graph.space = \"feature\"\n",
        "config.graph.use_topology = True\n",
        "config.graph.use_tangent = False\n",
        "config.graph.topo_k = TOPO_K\n",
        "config.graph.topo_maxdim = TOPO_MAXDIM\n",
        "config.graph.topo_preprocess = TOPO_PREPROCESS\n",
        "config.graph.topo_pca_dim = TOPO_PCA_DIM\n",
        "config.graph.topo_min_persistence = TOPO_MIN_PERSISTENCE\n",
        "\n",
        "config.detector.detector_type = \"topology_score\"\n",
        "config.detector.topo_percentile = TOPO_PERCENTILE\n",
        "config.detector.topo_cov_shrinkage = TOPO_COV_SHRINKAGE\n",
        "\n",
        "model = api.get_model(\"CNN\", config, num_classes=2, in_channels=3, feat_dim=128)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train (API)\n",
        "# Note: `bundle` was created in the dataset cell.\n",
        "model, history = api.train(\n",
        "    model,\n",
        "    bundle,\n",
        "    config,\n",
        "    device=str(config.device),\n",
        "    verbose=True,\n",
        "    return_history=True,\n",
        ")\n",
        "\n",
        "pred_test = api.predict(model, X_test, device=str(config.device), return_probs=False)\n",
        "test_acc = 100.0 * float(np.mean(pred_test == np.asarray(y_test, dtype=int)))\n",
        "print(f\"Test accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adversarial examples + success masks (API)\n",
        "X_adv_val = api.generate_adversarial(model, X_val, y_val, config, clip=bundle.meta.get(\"clip\"))\n",
        "X_adv_test = api.generate_adversarial(model, X_test, y_test, config, clip=bundle.meta.get(\"clip\"))\n",
        "\n",
        "EVAL_ONLY_SUCCESSFUL_ATTACKS = True\n",
        "FILTER_CLEAN_TO_CORRECT = True\n",
        "\n",
        "pred_val_clean, pred_val_adv, val_clean_correct, val_success = compute_success_mask(\n",
        "    model, X_val, X_adv_val, y_val, device=str(config.device)\n",
        ")\n",
        "pred_test_clean, pred_test_adv, test_clean_correct, test_success = compute_success_mask(\n",
        "    model, X_test, X_adv_test, y_test, device=str(config.device)\n",
        ")\n",
        "\n",
        "print(f\"Val successful attacks:  {val_success.sum()}/{len(val_success)} = {val_success.mean():.3f}\")\n",
        "print(f\"Test successful attacks: {test_success.sum()}/{len(test_success)} = {test_success.mean():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize a few successful attacks\n",
        "show_successful_attacks(\n",
        "    X_test, X_adv_test, y_test,\n",
        "    pred_test_clean, pred_test_adv,\n",
        "    test_success,\n",
        "    epsilon=EPSILON,\n",
        "    n_show=6,\n",
        "    seed=SEED,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reference embedding set from TRAIN\n",
        "Z_train = extract_features_batch(model, X_train, layer='penultimate', device=DEVICE)\n",
        "print(f\"Z_train: {Z_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Topology-score detector (API)\n",
        "clean_mask_val = val_clean_correct if FILTER_CLEAN_TO_CORRECT else np.ones(len(X_val), dtype=bool)\n",
        "clean_mask_test = test_clean_correct if FILTER_CLEAN_TO_CORRECT else np.ones(len(X_test), dtype=bool)\n",
        "adv_mask_val = val_success if EVAL_ONLY_SUCCESSFUL_ATTACKS else np.ones(len(X_adv_val), dtype=bool)\n",
        "adv_mask_test = test_success if EVAL_ONLY_SUCCESSFUL_ATTACKS else np.ones(len(X_adv_test), dtype=bool)\n",
        "\n",
        "X_val_clean_used, _ = api.subsample_masked(X_val, y_val, clean_mask_val, MAX_POINTS_FOR_SCORING, seed=SEED)\n",
        "X_test_clean_used, _ = api.subsample_masked(X_test, y_test, clean_mask_test, MAX_POINTS_FOR_SCORING, seed=SEED + 1)\n",
        "X_val_adv_used, _ = api.subsample_masked(X_adv_val, y_val, adv_mask_val, MAX_POINTS_FOR_SCORING, seed=SEED + 2)\n",
        "X_test_adv_used, _ = api.subsample_masked(X_adv_test, y_test, adv_mask_test, MAX_POINTS_FOR_SCORING, seed=SEED + 3)\n",
        "\n",
        "scores_val_clean = api.compute_scores(X_val_clean_used, model, bundle=bundle, cfg=config)\n",
        "scores_val_adv = api.compute_scores(X_val_adv_used, model, bundle=bundle, cfg=config)\n",
        "\n",
        "scores_test_clean = api.compute_scores(X_test_clean_used, model, bundle=bundle, cfg=config)\n",
        "scores_test_adv = api.compute_scores(X_test_adv_used, model, bundle=bundle, cfg=config)\n",
        "\n",
        "scores_val_all = api.concat_scores(scores_val_clean, scores_val_adv)\n",
        "any_key = next(iter(scores_val_all.keys()))\n",
        "labels_val = np.concatenate(\n",
        "    [np.zeros(len(scores_val_clean[any_key]), dtype=int), np.ones(len(scores_val_adv[any_key]), dtype=int)]\n",
        ")\n",
        "\n",
        "detector = api.fit_detector(scores_val_all, labels_val, config)\n",
        "\n",
        "scores_test_all = api.concat_scores(scores_test_clean, scores_test_adv)\n",
        "any_key_t = next(iter(scores_test_all.keys()))\n",
        "labels_test = np.concatenate(\n",
        "    [np.zeros(len(scores_test_clean[any_key_t]), dtype=int), np.ones(len(scores_test_adv[any_key_t]), dtype=int)]\n",
        ")\n",
        "\n",
        "raw_scores_test = np.asarray(detector.score(scores_test_all), dtype=float)\n",
        "metrics = api.evaluate_detection(labels_test, raw_scores_test)\n",
        "\n",
        "print(\"Detector performance (topology_mahalanobis):\")\n",
        "print(f\"  AUROC:     {metrics['roc_auc']:.4f}\")\n",
        "print(f\"  AUPRC:     {metrics['pr_auc']:.4f}\")\n",
        "print(f\"  FPR@95TPR: {metrics['fpr_at_tpr95']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mini CNN Image Classifier + Topology (Persistent Homology) Detector (Synthetic Images)\n",
        "\n",
        "This notebook extends the repository’s **topology-based detector** (`detector_type='topology_score'`) to an **image-like** setting using a **fully synthetic 2-class RGB dataset**.\n",
        "\n",
        "We will:\n",
        "\n",
        "- generate a simple synthetic image dataset (circles vs squares),\n",
        "- train a small CNN,\n",
        "- generate adversarial examples (FGSM/PGD) in pixel space,\n",
        "- extract penultimate-layer embeddings,\n",
        "- compute local persistent-homology (PH) summary features on kNN neighborhoods in embedding space,\n",
        "- fit a `TopologyScoreDetector` (Mahalanobis-to-clean + percentile threshold),\n",
        "- evaluate detection metrics (AUROC/AUPRC/FPR@95%TPR).\n",
        "\n",
        "Notes:\n",
        "- This uses **no torchvision** and performs **no dataset downloads**.\n",
        "- Persistent homology requires `ripser` (already in this repo’s `requirements.txt`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import importlib\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Project root\n",
        "CWD = os.getcwd()\n",
        "PROJECT_ROOT = os.path.abspath(os.path.join(CWD, \"..\")) if os.path.basename(CWD) == \"notebooks\" else os.path.abspath(CWD)\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "# Public pipeline API\n",
        "from src import api\n",
        "from src.utils import ExperimentConfig, set_seed\n",
        "\n",
        "from src.models import extract_features_batch\n",
        "from src.visualization import plot_roc_from_metrics, plot_confusion_matrix, plot_score_distributions_figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Dataset sizes (keep small for fast CPU runs + PH runtime)\n",
        "N_TRAIN = 2000\n",
        "N_VAL = 500\n",
        "N_TEST = 500\n",
        "\n",
        "# Model training\n",
        "EPOCHS = 8\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "\n",
        "# Attack settings (pixel-space; inputs in [0,1])\n",
        "ATTACK_TYPE = 'fgsm'  # 'fgsm' or 'pgd'\n",
        "EPSILON = 0.03        # typical for [0,1] images\n",
        "PGD_STEPS = 10\n",
        "PGD_STEP_SIZE = 0.007\n",
        "\n",
        "# Topology detector settings (computed in feature space)\n",
        "TOPO_K = 40                 # neighborhood size for local PH\n",
        "TOPO_MAXDIM = 1             # H0/H1\n",
        "TOPO_PREPROCESS = 'pca'      # helps in high-d embedding spaces\n",
        "TOPO_PCA_DIM = 10\n",
        "TOPO_MIN_PERSISTENCE = 1e-6\n",
        "\n",
        "TOPO_PERCENTILE = 95.0       # clean-score percentile threshold\n",
        "TOPO_COV_SHRINKAGE = 1e-3\n",
        "\n",
        "# Scoring subsampling (PH per point can be expensive)\n",
        "MAX_POINTS_FOR_SCORING = 250\n",
        "\n",
        "print(f\"DEVICE: {DEVICE}\")\n",
        "print(f\"Train/Val/Test: {N_TRAIN}/{N_VAL}/{N_TEST}\")\n",
        "print(f\"Attack: {ATTACK_TYPE}, eps={EPSILON}\")\n",
        "print(f\"Topology: k={TOPO_K}, maxdim={TOPO_MAXDIM}, preprocess={TOPO_PREPROCESS}({TOPO_PCA_DIM})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helpers (keep all reusable functions/classes here) — API version\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def load_dataset(\n",
        "    *,\n",
        "    n_train: int,\n",
        "    n_val: int,\n",
        "    n_test: int,\n",
        "    seed: int,\n",
        ") -> Tuple[str, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    data_cfg = ExperimentConfig(seed=seed, device=DEVICE)\n",
        "    total = int(n_train + n_val + n_test)\n",
        "    data_cfg.data.n_samples = total\n",
        "    data_cfg.data.train_ratio = float(n_train) / float(total)\n",
        "    data_cfg.data.val_ratio = float(n_val) / float(total)\n",
        "\n",
        "    b = api.get_dataset(\"synthetic_shapes_2class\", data_cfg)\n",
        "    return \"synthetic_shapes_2class\", b.X_train, b.y_train, b.X_val, b.y_val, b.X_test, b.y_test\n",
        "\n",
        "\n",
        "def plot_samples(X: np.ndarray, y: np.ndarray, *, title: str, n_show: int = 8):\n",
        "    fig, axes = plt.subplots(1, n_show, figsize=(2.2 * n_show, 2.2))\n",
        "    for i in range(n_show):\n",
        "        img = X[i].transpose(1, 2, 0)\n",
        "        axes[i].imshow(np.clip(img, 0, 1))\n",
        "        axes[i].set_title(f\"y={int(y[i])}\")\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def compute_success_mask(model: nn.Module, X_clean: np.ndarray, X_adv: np.ndarray, y: np.ndarray, device: str):\n",
        "    pred_clean = api.predict(model, X_clean, device=device, return_probs=False)\n",
        "    pred_adv = api.predict(model, X_adv, device=device, return_probs=False)\n",
        "    y = np.asarray(y, dtype=int)\n",
        "    clean_correct = pred_clean == y\n",
        "    success = api.attack_success_mask(model, X_clean, X_adv, y, device=device)\n",
        "    return pred_clean, pred_adv, clean_correct, success\n",
        "\n",
        "\n",
        "def show_successful_attacks(\n",
        "    X_clean: np.ndarray,\n",
        "    X_adv: np.ndarray,\n",
        "    y_true: np.ndarray,\n",
        "    pred_clean: np.ndarray,\n",
        "    pred_adv: np.ndarray,\n",
        "    success_mask: np.ndarray,\n",
        "    *,\n",
        "    epsilon: float,\n",
        "    n_show: int = 6,\n",
        "    seed: int = 0,\n",
        "):\n",
        "    idx = np.where(success_mask)[0]\n",
        "    if len(idx) == 0:\n",
        "        print(\"No successful attacks to show. Try increasing EPSILON / PGD_STEPS.\")\n",
        "        return\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    chosen = rng.choice(idx, size=min(n_show, len(idx)), replace=False)\n",
        "\n",
        "    fig, axes = plt.subplots(len(chosen), 2, figsize=(7, 3 * len(chosen)))\n",
        "    if len(chosen) == 1:\n",
        "        axes = np.expand_dims(axes, axis=0)\n",
        "\n",
        "    for r, i in enumerate(chosen):\n",
        "        clean = np.clip(X_clean[i].transpose(1, 2, 0), 0, 1)\n",
        "        adv = np.clip(X_adv[i].transpose(1, 2, 0), 0, 1)\n",
        "\n",
        "        axes[r, 0].imshow(clean)\n",
        "        axes[r, 0].axis(\"off\")\n",
        "        axes[r, 0].set_title(f\"clean: y={int(y_true[i])}, pred={int(pred_clean[i])}\")\n",
        "\n",
        "        axes[r, 1].imshow(adv)\n",
        "        axes[r, 1].axis(\"off\")\n",
        "        axes[r, 1].set_title(f\"adv: pred={int(pred_adv[i])}  (eps={epsilon})\")\n",
        "\n",
        "    plt.suptitle(f\"Successful attacks (n={len(idx)})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset (via public dataset registry)\n",
        "DATASET_NAME = \"synthetic_shapes_2class\"\n",
        "\n",
        "_data_cfg = ExperimentConfig(seed=SEED, device=DEVICE)\n",
        "_total = int(N_TRAIN + N_VAL + N_TEST)\n",
        "_data_cfg.data.n_samples = _total\n",
        "_data_cfg.data.train_ratio = float(N_TRAIN) / float(_total)\n",
        "_data_cfg.data.val_ratio = float(N_VAL) / float(_total)\n",
        "\n",
        "bundle = api.get_dataset(DATASET_NAME, _data_cfg)\n",
        "X_train, y_train = bundle.X_train, bundle.y_train\n",
        "X_val, y_val = bundle.X_val, bundle.y_val\n",
        "X_test, y_test = bundle.X_test, bundle.y_test\n",
        "\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"X_train: {X_train.shape}, y_train mean: {y_train.mean():.3f}\")\n",
        "print(f\"X_val:   {X_val.shape}, y_val mean:   {y_val.mean():.3f}\")\n",
        "print(f\"X_test:  {X_test.shape}, y_test mean:  {y_test.mean():.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visual sanity-check\n",
        "plot_samples(X_train, y_train, title=f\"{DATASET_NAME}: first samples\", n_show=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model + experiment config (API)\n",
        "config = ExperimentConfig(seed=SEED, device=DEVICE)\n",
        "\n",
        "# Training\n",
        "config.model.epochs = EPOCHS\n",
        "config.model.batch_size = BATCH_SIZE\n",
        "config.model.learning_rate = LR\n",
        "config.model.output_dim = 2\n",
        "\n",
        "# Attack\n",
        "config.attack.attack_type = ATTACK_TYPE\n",
        "config.attack.epsilon = EPSILON\n",
        "config.attack.num_steps = PGD_STEPS\n",
        "config.attack.step_size = PGD_STEP_SIZE\n",
        "config.attack.random_start = True\n",
        "\n",
        "# Topology features computed in feature space\n",
        "config.graph.space = \"feature\"\n",
        "config.graph.use_topology = True\n",
        "config.graph.use_tangent = False\n",
        "config.graph.topo_k = TOPO_K\n",
        "config.graph.topo_maxdim = TOPO_MAXDIM\n",
        "config.graph.topo_preprocess = TOPO_PREPROCESS\n",
        "config.graph.topo_pca_dim = TOPO_PCA_DIM\n",
        "config.graph.topo_min_persistence = TOPO_MIN_PERSISTENCE\n",
        "\n",
        "# Topology-score detector\n",
        "config.detector.detector_type = \"topology_score\"\n",
        "config.detector.topo_percentile = TOPO_PERCENTILE\n",
        "config.detector.topo_cov_shrinkage = TOPO_COV_SHRINKAGE\n",
        "\n",
        "model = api.get_model(\"CNN\", config, num_classes=2, in_channels=3, feat_dim=128)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train (API)\n",
        "model, history = api.train(\n",
        "    model,\n",
        "    bundle,\n",
        "    config,\n",
        "    device=str(config.device),\n",
        "    verbose=True,\n",
        "    return_history=True,\n",
        ")\n",
        "\n",
        "pred_test = api.predict(model, X_test, device=str(config.device), return_probs=False)\n",
        "test_acc = 100.0 * float(np.mean(pred_test == np.asarray(y_test, dtype=int)))\n",
        "print(f\"Test accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "# (Optional) training curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(history['train_loss'], label='train'); axes[0].plot(history['val_loss'], label='val'); axes[0].set_title('Loss'); axes[0].grid(True, alpha=0.3); axes[0].legend()\n",
        "axes[1].plot(history['train_acc'], label='train'); axes[1].plot(history['val_acc'], label='val'); axes[1].set_title('Accuracy (%)'); axes[1].grid(True, alpha=0.3); axes[1].legend()\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adversarial examples + success masks (API)\n",
        "X_adv_val = api.generate_adversarial(model, X_val, y_val, config, clip=bundle.meta.get(\"clip\"))\n",
        "X_adv_test = api.generate_adversarial(model, X_test, y_test, config, clip=bundle.meta.get(\"clip\"))\n",
        "\n",
        "# Successful = model correct on clean AND wrong on adv\n",
        "EVAL_ONLY_SUCCESSFUL_ATTACKS = True\n",
        "FILTER_CLEAN_TO_CORRECT = True\n",
        "\n",
        "pred_val_clean, pred_val_adv, val_clean_correct, val_success = compute_success_mask(\n",
        "    model, X_val, X_adv_val, y_val, device=str(config.device)\n",
        ")\n",
        "pred_test_clean, pred_test_adv, test_clean_correct, test_success = compute_success_mask(\n",
        "    model, X_test, X_adv_test, y_test, device=str(config.device)\n",
        ")\n",
        "\n",
        "print(f\"Val successful attacks:  {val_success.sum()}/{len(val_success)} = {val_success.mean():.3f}\")\n",
        "print(f\"Test successful attacks: {test_success.sum()}/{len(test_success)} = {test_success.mean():.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize a few successful attacks\n",
        "show_successful_attacks(\n",
        "    X_test,\n",
        "    X_adv_test,\n",
        "    y_test,\n",
        "    pred_test_clean,\n",
        "    pred_test_adv,\n",
        "    test_success,\n",
        "    epsilon=EPSILON,\n",
        "    n_show=6,\n",
        "    seed=SEED,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reference embedding set from TRAIN\n",
        "Z_train = extract_features_batch(model, X_train, layer='penultimate', device=DEVICE)\n",
        "print(f\"Z_train: {Z_train.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Topology-score detector (PH feature vector -> Mahalanobis -> threshold) — API\n",
        "\n",
        "# Choose which points participate in scoring\n",
        "clean_mask_val = val_clean_correct if FILTER_CLEAN_TO_CORRECT else np.ones(len(X_val), dtype=bool)\n",
        "clean_mask_test = test_clean_correct if FILTER_CLEAN_TO_CORRECT else np.ones(len(X_test), dtype=bool)\n",
        "\n",
        "adv_mask_val = val_success if EVAL_ONLY_SUCCESSFUL_ATTACKS else np.ones(len(X_adv_val), dtype=bool)\n",
        "adv_mask_test = test_success if EVAL_ONLY_SUCCESSFUL_ATTACKS else np.ones(len(X_adv_test), dtype=bool)\n",
        "\n",
        "seed0 = int(getattr(config, \"seed\", 42))\n",
        "X_val_clean_used, _ = api.subsample_masked(X_val, y_val, clean_mask_val, MAX_POINTS_FOR_SCORING, seed=seed0)\n",
        "X_test_clean_used, _ = api.subsample_masked(X_test, y_test, clean_mask_test, MAX_POINTS_FOR_SCORING, seed=seed0 + 1)\n",
        "X_val_adv_used, _ = api.subsample_masked(X_adv_val, y_val, adv_mask_val, MAX_POINTS_FOR_SCORING, seed=seed0 + 2)\n",
        "X_test_adv_used, _ = api.subsample_masked(X_adv_test, y_test, adv_mask_test, MAX_POINTS_FOR_SCORING, seed=seed0 + 3)\n",
        "\n",
        "print(f\"Scoring sizes: val clean={len(X_val_clean_used)}, val adv={len(X_val_adv_used)}\")\n",
        "print(f\"Scoring sizes: test clean={len(X_test_clean_used)}, test adv={len(X_test_adv_used)}\")\n",
        "\n",
        "# Compute scores (includes topo_* keys when config.graph.use_topology=True)\n",
        "scores_val_clean = api.compute_scores(X_val_clean_used, model, bundle=bundle, cfg=config)\n",
        "scores_val_adv = api.compute_scores(X_val_adv_used, model, bundle=bundle, cfg=config)\n",
        "\n",
        "scores_test_clean = api.compute_scores(X_test_clean_used, model, bundle=bundle, cfg=config)\n",
        "scores_test_adv = api.compute_scores(X_test_adv_used, model, bundle=bundle, cfg=config)\n",
        "\n",
        "# Train detector on val\n",
        "scores_val_all = api.concat_scores(scores_val_clean, scores_val_adv)\n",
        "any_key = next(iter(scores_val_all.keys()))\n",
        "labels_val = np.concatenate([\n",
        "    np.zeros(len(scores_val_clean[any_key]), dtype=int),\n",
        "    np.ones(len(scores_val_adv[any_key]), dtype=int),\n",
        "])\n",
        "\n",
        "detector = api.fit_detector(scores_val_all, labels_val, config)\n",
        "\n",
        "# Evaluate on test\n",
        "scores_test_all = api.concat_scores(scores_test_clean, scores_test_adv)\n",
        "any_key_t = next(iter(scores_test_all.keys()))\n",
        "labels_test = np.concatenate([\n",
        "    np.zeros(len(scores_test_clean[any_key_t]), dtype=int),\n",
        "    np.ones(len(scores_test_adv[any_key_t]), dtype=int),\n",
        "])\n",
        "\n",
        "raw_scores_test = np.asarray(detector.score(scores_test_all), dtype=float)\n",
        "metrics = api.evaluate_detection(labels_test, raw_scores_test)\n",
        "\n",
        "thr = float(getattr(detector, \"threshold\", np.nan))\n",
        "\n",
        "print(\"\\nDetector performance (topology_mahalanobis score):\")\n",
        "print(f\"  AUROC:        {metrics['roc_auc']:.4f}\")\n",
        "print(f\"  AUPRC:        {metrics['pr_auc']:.4f}\")\n",
        "print(f\"  FPR@95%TPR:   {metrics['fpr_at_tpr95']:.4f}\")\n",
        "print(f\"  threshold:    {thr:.4f}\")\n",
        "\n",
        "# Quick plots (shared utilities)\n",
        "plot_roc_from_metrics(\n",
        "    metrics,\n",
        "    title=f\"ROC: {DATASET_NAME} ({ATTACK_TYPE}, eps={EPSILON})\",\n",
        ")\n",
        "\n",
        "if np.isfinite(thr):\n",
        "    plot_confusion_matrix(labels_test, y_scores=raw_scores_test, threshold=thr, labels=(\"clean\", \"adv\"))\n",
        "\n",
        "raw_clean = raw_scores_test[: len(X_test_clean_used)]\n",
        "raw_adv = raw_scores_test[len(X_test_clean_used):]\n",
        "plot_score_distributions_figure(\n",
        "    raw_clean,\n",
        "    raw_adv,\n",
        "    score_name=\"topology_mahalanobis score\",\n",
        "    title=\"Topology score distribution (test)\",\n",
        "    bins=40,\n",
        "    threshold=thr,\n",
        "    labels=(\"clean\", \"adversarial\"),\n",
        "    alpha=0.6,\n",
        "    density=True,\n",
        "    figsize=(7, 4),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Detector Steps with PH Diagrams\n",
        "\n",
        "This section visualizes the detector pipeline step-by-step, showing:\n",
        "1. Local neighborhood point cloud (in feature space)\n",
        "2. Persistence diagrams (H0 and H1)\n",
        "3. Topology summary features\n",
        "4. Final detector score\n",
        "\n",
        "We'll compare a clean non-flagged sample with an adversarial flagged sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to compute topology features with diagrams for a single point\n",
        "from typing import Sequence\n",
        "\n",
        "def compute_topology_feature_scores_with_diagrams(\n",
        "    X_point: np.ndarray,\n",
        "    *,\n",
        "    model: nn.Module,\n",
        "    Z_train: np.ndarray,\n",
        "    graph_cfg,\n",
        "    device: str,\n",
        "    layer: str = 'penultimate',\n",
        ") -> Tuple[Dict[str, float], Sequence[np.ndarray], np.ndarray]:\n",
        "    \"\"\"Compute topology features with diagrams for a single point (for visualization).\"\"\"\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "    \n",
        "    if graph_cfg.space == 'feature':\n",
        "        # For images, preserve dimensions: add batch dimension without flattening\n",
        "        # X_point is likely (C, H, W) or (H, W, C), we need (1, C, H, W) or (1, H, W, C)\n",
        "        if X_point.ndim == 3:\n",
        "            # Add batch dimension: (C, H, W) -> (1, C, H, W) or (H, W, C) -> (1, H, W, C)\n",
        "            X_point_batch = X_point[None, ...]\n",
        "        elif X_point.ndim == 2:\n",
        "            # For 2D data (like two-moons), flatten: (D,) -> (1, D)\n",
        "            X_point_batch = X_point.reshape(1, -1)\n",
        "        else:\n",
        "            # Already has batch dimension or is 1D\n",
        "            X_point_batch = X_point if X_point.ndim > 1 else X_point.reshape(1, -1)\n",
        "        Z_point = extract_features_batch(model, X_point_batch, layer=layer, device=device)[0]\n",
        "    else:\n",
        "        Z_point = X_point\n",
        "    \n",
        "    topo_cfg = TopologyConfig(\n",
        "        neighborhood_k=int(getattr(graph_cfg, 'topo_k', 50)),\n",
        "        maxdim=int(getattr(graph_cfg, 'topo_maxdim', 1)),\n",
        "        metric=str(getattr(graph_cfg, 'topo_metric', 'euclidean')),\n",
        "        thresh=getattr(graph_cfg, 'topo_thresh', None),\n",
        "        min_persistence=float(getattr(graph_cfg, 'topo_min_persistence', 1e-6)),\n",
        "        preprocess=str(getattr(graph_cfg, 'topo_preprocess', 'none')),\n",
        "        pca_dim=int(getattr(graph_cfg, 'topo_pca_dim', 10)),\n",
        "    )\n",
        "    \n",
        "    nbrs = NearestNeighbors(\n",
        "        n_neighbors=min(topo_cfg.neighborhood_k, len(Z_train)),\n",
        "        metric=topo_cfg.metric,\n",
        "    ).fit(Z_train)\n",
        "    \n",
        "    # Get neighborhood\n",
        "    _, idx = nbrs.kneighbors(Z_point.reshape(1, -1))\n",
        "    neighborhood = Z_train[idx[0]]\n",
        "    # Ensure the query point participates in the complex\n",
        "    cloud = np.vstack([Z_point.reshape(1, -1), neighborhood])\n",
        "    \n",
        "    # Compute PH features with diagrams\n",
        "    features, diagrams = local_persistence_features(cloud, topo_cfg, return_diagrams=True)\n",
        "    \n",
        "    return features, diagrams, cloud\n",
        "\n",
        "# Import visualization functions\n",
        "from src.visualization import (\n",
        "    plot_persistence_diagram, \n",
        "    plot_topology_summary_features, \n",
        "    plot_local_neighborhood\n",
        ")\n",
        "from src.detectors import predict_graph_detector\n",
        "\n",
        "# Select examples for visualization\n",
        "# 1. Clean non-flagged sample (low detector score)\n",
        "clean_scores = detector.score(scores_test_clean)\n",
        "clean_idx = np.argmin(clean_scores)  # Lowest score = most clean-like\n",
        "print(f\"Selected clean sample: index {clean_idx}, score={clean_scores[clean_idx]:.4f}\")\n",
        "\n",
        "# 2. Adversarial flagged sample (high detector score)\n",
        "adv_scores = detector.score(scores_test_adv)\n",
        "adv_idx = np.argmax(adv_scores)  # Highest score among adversarial\n",
        "print(f\"Selected adversarial sample: index {adv_idx}, score={adv_scores[adv_idx]:.4f}\")\n",
        "\n",
        "# Get predictions for context\n",
        "predictions_test, _ = predict_graph_detector(detector, scores_test_all)\n",
        "any_key = next(iter(scores_test_clean.keys()))\n",
        "clean_pred_idx = clean_idx\n",
        "adv_pred_idx = len(scores_test_clean[any_key]) + adv_idx\n",
        "print(f\"Clean sample flagged: {predictions_test[clean_pred_idx]}\")\n",
        "print(f\"Adversarial sample flagged: {predictions_test[adv_pred_idx]}\")\n",
        "\n",
        "# Compute scores with diagrams for both samples\n",
        "print(\"\\nComputing topology features with diagrams for clean sample...\")\n",
        "clean_features, clean_diagrams, clean_cloud = compute_topology_feature_scores_with_diagrams(\n",
        "    X_test_clean_used[clean_idx], model=model, Z_train=Z_train, \n",
        "    graph_cfg=config.graph, device=DEVICE\n",
        ")\n",
        "\n",
        "print(\"Computing topology features with diagrams for adversarial sample...\")\n",
        "adv_features, adv_diagrams, adv_cloud = compute_topology_feature_scores_with_diagrams(\n",
        "    X_test_adv_used[adv_idx], model=model, Z_train=Z_train, \n",
        "    graph_cfg=config.graph, device=DEVICE\n",
        ")\n",
        "\n",
        "# Get detector scores\n",
        "clean_detector_score = clean_scores[clean_idx]\n",
        "adv_detector_score = adv_scores[adv_idx]\n",
        "\n",
        "print(f\"\\nDetector scores:\")\n",
        "print(f\"  Clean sample: {clean_detector_score:.4f} (threshold: {detector.threshold:.4f})\")\n",
        "print(f\"  Adversarial sample: {adv_detector_score:.4f} (threshold: {detector.threshold:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize local neighborhood point clouds\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# Clean sample neighborhood\n",
        "plot_local_neighborhood(\n",
        "    clean_cloud,\n",
        "    query_point=clean_cloud[0] if len(clean_cloud) > 0 else None,\n",
        "    title=f\"Clean Sample Neighborhood\\n(Detector Score: {clean_detector_score:.4f})\",\n",
        "    ax=axes[0],\n",
        "    max_dims=2\n",
        ")\n",
        "\n",
        "# Adversarial sample neighborhood\n",
        "plot_local_neighborhood(\n",
        "    adv_cloud,\n",
        "    query_point=adv_cloud[0] if len(adv_cloud) > 0 else None,\n",
        "    title=f\"Adversarial Sample Neighborhood\\n(Detector Score: {adv_detector_score:.4f})\",\n",
        "    ax=axes[1],\n",
        "    max_dims=2\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize persistence diagrams (H0 and H1)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
        "\n",
        "# Clean sample H0\n",
        "if len(clean_diagrams) > 0 and clean_diagrams[0].size > 0:\n",
        "    plot_persistence_diagram(\n",
        "        clean_diagrams[0],\n",
        "        dimension=0,\n",
        "        title=f\"Clean Sample - H0 Persistence Diagram\\n(Score: {clean_detector_score:.4f})\",\n",
        "        ax=axes[0, 0],\n",
        "        min_persistence=config.graph.topo_min_persistence\n",
        "    )\n",
        "else:\n",
        "    axes[0, 0].text(0.5, 0.5, 'No H0 features', ha='center', va='center', transform=axes[0, 0].transAxes)\n",
        "    axes[0, 0].set_title(f\"Clean Sample - H0 Persistence Diagram\\n(Score: {clean_detector_score:.4f})\")\n",
        "\n",
        "# Clean sample H1\n",
        "if len(clean_diagrams) > 1 and clean_diagrams[1].size > 0:\n",
        "    plot_persistence_diagram(\n",
        "        clean_diagrams[1],\n",
        "        dimension=1,\n",
        "        title=f\"Clean Sample - H1 Persistence Diagram\\n(Score: {clean_detector_score:.4f})\",\n",
        "        ax=axes[0, 1],\n",
        "        min_persistence=config.graph.topo_min_persistence\n",
        "    )\n",
        "else:\n",
        "    axes[0, 1].text(0.5, 0.5, 'No H1 features', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
        "    axes[0, 1].set_title(f\"Clean Sample - H1 Persistence Diagram\\n(Score: {clean_detector_score:.4f})\")\n",
        "\n",
        "# Adversarial sample H0\n",
        "if len(adv_diagrams) > 0 and adv_diagrams[0].size > 0:\n",
        "    plot_persistence_diagram(\n",
        "        adv_diagrams[0],\n",
        "        dimension=0,\n",
        "        title=f\"Adversarial Sample - H0 Persistence Diagram\\n(Score: {adv_detector_score:.4f})\",\n",
        "        ax=axes[1, 0],\n",
        "        min_persistence=config.graph.topo_min_persistence\n",
        "    )\n",
        "else:\n",
        "    axes[1, 0].text(0.5, 0.5, 'No H0 features', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
        "    axes[1, 0].set_title(f\"Adversarial Sample - H0 Persistence Diagram\\n(Score: {adv_detector_score:.4f})\")\n",
        "\n",
        "# Adversarial sample H1\n",
        "if len(adv_diagrams) > 1 and adv_diagrams[1].size > 0:\n",
        "    plot_persistence_diagram(\n",
        "        adv_diagrams[1],\n",
        "        dimension=1,\n",
        "        title=f\"Adversarial Sample - H1 Persistence Diagram\\n(Score: {adv_detector_score:.4f})\",\n",
        "        ax=axes[1, 1],\n",
        "        min_persistence=config.graph.topo_min_persistence\n",
        "    )\n",
        "else:\n",
        "    axes[1, 1].text(0.5, 0.5, 'No H1 features', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
        "    axes[1, 1].set_title(f\"Adversarial Sample - H1 Persistence Diagram\\n(Score: {adv_detector_score:.4f})\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize topology summary features\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
        "\n",
        "# Clean sample features\n",
        "plot_topology_summary_features(\n",
        "    clean_features,\n",
        "    title=f\"Clean Sample - Topology Summary Features\\n(Detector Score: {clean_detector_score:.4f}, Threshold: {detector.threshold:.4f})\",\n",
        "    ax=axes[0]\n",
        ")\n",
        "\n",
        "# Adversarial sample features\n",
        "plot_topology_summary_features(\n",
        "    adv_features,\n",
        "    title=f\"Adversarial Sample - Topology Summary Features\\n(Detector Score: {adv_detector_score:.4f}, Threshold: {detector.threshold:.4f})\",\n",
        "    ax=axes[1]\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print feature comparison\n",
        "print(\"\\nTopology Feature Comparison:\")\n",
        "print(\"=\" * 80)\n",
        "for key in sorted(clean_features.keys()):\n",
        "    clean_val = clean_features.get(key, 0.0)\n",
        "    adv_val = adv_features.get(key, 0.0)\n",
        "    diff = adv_val - clean_val\n",
        "    print(f\"{key:30s} Clean: {clean_val:8.4f}  Adversarial: {adv_val:8.4f}  Diff: {diff:8.4f}\")\n",
        "print(\"=\" * 80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
