{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hypothesis validation notebook (MNIST)\n",
        "\n",
        "**Hypothesis (operational):** In representation space, clean samples exhibit class-conditional local regularity. Adversarial samples are enriched among points showing decisionâ€“geometry inconsistency (e.g., class-mixed neighborhoods; atypical for predicted class relative to alternatives).\n",
        "\n",
        "Notes for local runtime:\n",
        "- MNIST is larger; we cap PH scoring with `MAX_POINTS_FOR_SCORING`.\n",
        "- `IMAGE` requires `torchvision` and (unless already present) an MNIST download.\n",
        "- You can set `cfg.data.root` and `cfg.data.download=True` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "90a90c3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import sys\n",
        "import time\n",
        "from dataclasses import replace\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "repo_root = pathlib.Path('..').resolve()\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.append(str(repo_root))\n",
        "\n",
        "from src.api import (\n",
        "    get_dataset,\n",
        "    get_model,\n",
        "    train,\n",
        "    generate_adversarial,\n",
        "    compute_scores,\n",
        "    concat_scores,\n",
        "    fit_detector,\n",
        ")\n",
        "from src.evaluation import evaluate_detector\n",
        "from src.models import get_model_predictions, extract_features_batch\n",
        "from src.utils import ExperimentConfig, DataConfig, ModelConfig, AttackConfig, GraphConfig, DetectorConfig\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.decomposition import PCA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "576a09f5",
      "metadata": {},
      "source": [
        "### Config\n",
        "\n",
        "You may need to set `download=True` if MNIST isn't present under `root`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0ed0fba8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExperimentConfig(data=DataConfig(n_samples=1000, noise=0.1, random_state=42, train_ratio=0.8, val_ratio=0.2, test_ratio=0.0, root='./data', download=False, mech_sigma_tangent=0.25, mech_sigma_normal=0.05, mech_class_aniso_scale=1.5, mech_warp_strength=0.0), model=ModelConfig(input_dim=2, hidden_dims=[64, 32], output_dim=2, activation='relu', learning_rate=0.001, epochs=2, batch_size=128, weight_decay=0.0001, random_state=42), attack=AttackConfig(attack_type='fgsm', epsilon=0.1, num_steps=10, step_size=0.01, random_start=True), ood=OODConfig(enabled=False, method='feature_shuffle', severity=1.0, seed=None, batch_size=128, patch_size=4, blur_kernel_size=5, blur_sigma=1.0, saltpepper_p=0.05), graph=GraphConfig(k=10, sigma=None, space='feature', feature_layer='penultimate', normalized_laplacian=True, use_diffusion=False, diffusion_components=10, use_tangent=True, tangent_k=20, tangent_dim=None, tangent_var_threshold=0.9, tangent_dim_min=2, tangent_dim_max=None, use_topology=True, topo_k=30, topo_maxdim=1, topo_metric='euclidean', topo_thresh=None, topo_min_persistence=1e-06, topo_preprocess='pca', topo_pca_dim=10, topo_neighbor_mode='global', topo_k_list=None, topo_metric_normalization='none', topo_whiten_ridge=0.001), detector=DetectorConfig(score_type='combined', alpha=0.5, beta=0.5, detector_type='topology_score', calibration_method='isotonic', topo_feature_keys=None, topo_cov_shrinkage=0.001, topo_percentile=95.0, topo_class_conditional=False, topo_class_scoring_mode='min_over_classes', topo_min_clean_per_class=5), seed=42, device='cpu')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SEED = 42\n",
        "MAX_POINTS_FOR_SCORING = 200\n",
        "\n",
        "# Dataset reduction (set these to make MNIST faster/lighter)\n",
        "# Default below is a \"fast\" setting: 10 classes, but fewer samples per split.\n",
        "INCLUDE_CLASSES = [0, 1, 2]  # e.g. [0, 1, 2] or [3, 5]\n",
        "RELABEL_CLASSES = True  # if True (and INCLUDE_CLASSES != None), map included classes -> 0..C-1\n",
        "\n",
        "# Choose ONE of the following (or combine max + per-class cap):\n",
        "TRAIN_MAX_N = None          # e.g. 8000\n",
        "VAL_MAX_N = None            # e.g. 2000\n",
        "TEST_MAX_N = None           # e.g. 2000\n",
        "\n",
        "# Fast defaults (roughly: train=2000, val=500, test=1000 for MNIST)\n",
        "TRAIN_PER_CLASS_N = 200\n",
        "VAL_PER_CLASS_N = 50\n",
        "TEST_PER_CLASS_N = 100\n",
        "\n",
        "SUBSAMPLE_STRATIFIED = True # if using *_MAX_N, keep classes roughly balanced\n",
        "\n",
        "\n",
        "def reduce_image_bundle(\n",
        "    bundle,\n",
        "    *,\n",
        "    include_classes=None,\n",
        "    relabel: bool = True,\n",
        "    train_max_n=None,\n",
        "    val_max_n=None,\n",
        "    test_max_n=None,\n",
        "    train_per_class_n=None,\n",
        "    val_per_class_n=None,\n",
        "    test_per_class_n=None,\n",
        "    stratified: bool = True,\n",
        "    seed: int = 0,\n",
        "):\n",
        "    \"\"\"Filter + subsample an IMAGE bundle (e.g. MNIST) in-place and return it.\"\"\"\n",
        "\n",
        "    def _as_int_labels(y):\n",
        "        return np.asarray(y, dtype=int)\n",
        "\n",
        "    def _filter_classes(X, y, classes):\n",
        "        if classes is None:\n",
        "            return np.asarray(X), _as_int_labels(y)\n",
        "        classes_arr = np.asarray(list(classes), dtype=int)\n",
        "        keep = np.isin(_as_int_labels(y), classes_arr)\n",
        "        return np.asarray(X)[keep], _as_int_labels(y)[keep]\n",
        "\n",
        "    def _maybe_relabel(y, classes):\n",
        "        if classes is None or not relabel:\n",
        "            return _as_int_labels(y), None\n",
        "        ordered = list(map(int, classes))\n",
        "        ordered = sorted(set(ordered))\n",
        "        mapping = {c: i for i, c in enumerate(ordered)}\n",
        "        y_in = _as_int_labels(y)\n",
        "        y_out = np.array([mapping[int(v)] for v in y_in], dtype=int)\n",
        "        return y_out, mapping\n",
        "\n",
        "    def _stratified_take(y, n_take, rng):\n",
        "        y = _as_int_labels(y)\n",
        "        classes = np.unique(y)\n",
        "        if len(classes) == 0:\n",
        "            return np.array([], dtype=int)\n",
        "        base = int(n_take) // int(len(classes))\n",
        "        rem = int(n_take) % int(len(classes))\n",
        "        idx_all = []\n",
        "        for i, c in enumerate(classes):\n",
        "            c_idx = np.flatnonzero(y == c)\n",
        "            want = base + (1 if i < rem else 0)\n",
        "            want = min(len(c_idx), int(want))\n",
        "            if want > 0:\n",
        "                idx_all.append(rng.choice(c_idx, size=want, replace=False))\n",
        "        if not idx_all:\n",
        "            return np.array([], dtype=int)\n",
        "        idx = np.concatenate(idx_all).astype(int)\n",
        "        rng.shuffle(idx)\n",
        "        return idx\n",
        "\n",
        "    def _subsample(X, y, *, max_n=None, per_class_n=None, rng):\n",
        "        X = np.asarray(X)\n",
        "        y = _as_int_labels(y)\n",
        "        n = len(y)\n",
        "        if n == 0:\n",
        "            return X, y\n",
        "\n",
        "        idx = np.arange(n, dtype=int)\n",
        "\n",
        "        if per_class_n is not None:\n",
        "            take_idx = []\n",
        "            for c in np.unique(y):\n",
        "                c_idx = np.flatnonzero(y == c)\n",
        "                want = min(len(c_idx), int(per_class_n))\n",
        "                if want > 0:\n",
        "                    take_idx.append(rng.choice(c_idx, size=want, replace=False))\n",
        "            idx = np.concatenate(take_idx).astype(int) if take_idx else np.array([], dtype=int)\n",
        "            rng.shuffle(idx)\n",
        "\n",
        "        if max_n is not None and len(idx) > int(max_n):\n",
        "            y_idx = y[idx]\n",
        "            if stratified:\n",
        "                keep_rel = _stratified_take(y_idx, int(max_n), rng)\n",
        "                idx = idx[keep_rel]\n",
        "            else:\n",
        "                idx = rng.choice(idx, size=int(max_n), replace=False)\n",
        "\n",
        "        return X[idx], y[idx]\n",
        "\n",
        "    rng = np.random.default_rng(int(seed))\n",
        "\n",
        "    # 1) class filter (consistent across splits)\n",
        "    X_tr, y_tr = _filter_classes(bundle.X_train, bundle.y_train, include_classes)\n",
        "    X_va, y_va = _filter_classes(bundle.X_val, bundle.y_val, include_classes)\n",
        "    X_te, y_te = _filter_classes(bundle.X_test, bundle.y_test, include_classes)\n",
        "\n",
        "    # 2) optional relabel\n",
        "    y_tr, mapping = _maybe_relabel(y_tr, include_classes)\n",
        "    y_va, _ = _maybe_relabel(y_va, include_classes)\n",
        "    y_te, _ = _maybe_relabel(y_te, include_classes)\n",
        "\n",
        "    # 3) subsample each split\n",
        "    X_tr, y_tr = _subsample(X_tr, y_tr, max_n=train_max_n, per_class_n=train_per_class_n, rng=rng)\n",
        "    X_va, y_va = _subsample(X_va, y_va, max_n=val_max_n, per_class_n=val_per_class_n, rng=rng)\n",
        "    X_te, y_te = _subsample(X_te, y_te, max_n=test_max_n, per_class_n=test_per_class_n, rng=rng)\n",
        "\n",
        "    # 4) build updated meta\n",
        "    meta = dict(getattr(bundle, 'meta', {}) or {})\n",
        "    if include_classes is not None:\n",
        "        meta['included_classes'] = list(map(int, include_classes))\n",
        "    if mapping is not None:\n",
        "        meta['class_relabel_map'] = {int(k): int(v) for k, v in mapping.items()}\n",
        "        meta['num_classes'] = int(len(set(mapping.values())))\n",
        "\n",
        "    # 5) return a NEW bundle (DatasetBundle is frozen)\n",
        "    from dataclasses import replace as _replace\n",
        "\n",
        "    return _replace(\n",
        "        bundle,\n",
        "        X_train=X_tr,\n",
        "        y_train=y_tr,\n",
        "        X_val=X_va,\n",
        "        y_val=y_va,\n",
        "        X_test=X_te,\n",
        "        y_test=y_te,\n",
        "        meta=meta,\n",
        "    )\n",
        "\n",
        "\n",
        "cfg_base = ExperimentConfig(\n",
        "    seed=SEED,\n",
        "    device='cpu',\n",
        "    data=DataConfig(\n",
        "        train_ratio=0.8,\n",
        "        val_ratio=0.2,\n",
        "        test_ratio=0.0,  # torchvision datasets already have test split; registry uses it\n",
        "        root='./data',\n",
        "        download=False,\n",
        "    ),\n",
        "    model=ModelConfig(epochs=2, batch_size=128, learning_rate=1e-3, weight_decay=1e-4),\n",
        "    attack=AttackConfig(attack_type='fgsm', epsilon=0.1),\n",
        "    graph=GraphConfig(\n",
        "        space='feature',\n",
        "        feature_layer='penultimate',\n",
        "        use_topology=True,\n",
        "        topo_k=30,\n",
        "        topo_preprocess='pca',\n",
        "        topo_pca_dim=10,\n",
        "        topo_maxdim=1,\n",
        "        topo_neighbor_mode='global',\n",
        "        topo_metric_normalization='none',\n",
        "        topo_whiten_ridge=1e-3,\n",
        "        topo_k_list=None,\n",
        "    ),\n",
        "    detector=DetectorConfig(\n",
        "        detector_type='topology_score',\n",
        "        topo_percentile=95.0,\n",
        "        topo_cov_shrinkage=1e-3,\n",
        "        topo_class_conditional=False,\n",
        "        topo_class_scoring_mode='min_over_classes',\n",
        "        topo_min_clean_per_class=5,\n",
        "    ),\n",
        ")\n",
        "cfg_base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6981ac37",
      "metadata": {},
      "source": [
        "### Load dataset + train model once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2927e787",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train/val/test shapes: (600, 1, 28, 28) (150, 1, 28, 28) (300, 1, 28, 28)\n",
            "Included classes: [0, 1, 2] (relabel= True )\n",
            "Train class counts: {np.int64(0): np.int64(200), np.int64(1): np.int64(200), np.int64(2): np.int64(200)}\n"
          ]
        }
      ],
      "source": [
        "bundle = get_dataset('IMAGE', cfg_base, overrides={\"download\": True})\n",
        "\n",
        "# Optional: reduce dataset size/classes for faster runs\n",
        "bundle = reduce_image_bundle(\n",
        "    bundle,\n",
        "    include_classes=INCLUDE_CLASSES,\n",
        "    relabel=RELABEL_CLASSES,\n",
        "    train_max_n=TRAIN_MAX_N,\n",
        "    val_max_n=VAL_MAX_N,\n",
        "    test_max_n=TEST_MAX_N,\n",
        "    train_per_class_n=TRAIN_PER_CLASS_N,\n",
        "    val_per_class_n=VAL_PER_CLASS_N,\n",
        "    test_per_class_n=TEST_PER_CLASS_N,\n",
        "    stratified=SUBSAMPLE_STRATIFIED,\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "# Infer number of classes after optional relabeling\n",
        "_y_train_int = np.asarray(bundle.y_train, dtype=int)\n",
        "if (INCLUDE_CLASSES is not None) and (not RELABEL_CLASSES):\n",
        "    # Labels might be e.g. {3, 5}; keep output dim large enough for raw labels.\n",
        "    num_classes = int(bundle.meta.get('num_classes', int(_y_train_int.max()) + 1))\n",
        "else:\n",
        "    num_classes = int(bundle.meta.get('num_classes', len(np.unique(_y_train_int))))\n",
        "\n",
        "in_channels = int(bundle.X_train.shape[1])\n",
        "\n",
        "print('Train/val/test shapes:', bundle.X_train.shape, bundle.X_val.shape, bundle.X_test.shape)\n",
        "if INCLUDE_CLASSES is not None:\n",
        "    print('Included classes:', INCLUDE_CLASSES, '(relabel=', RELABEL_CLASSES, ')')\n",
        "print('Train class counts:', dict(zip(*np.unique(np.asarray(bundle.y_train, dtype=int), return_counts=True))))\n",
        "\n",
        "model = get_model('CNN', cfg_base, num_classes=num_classes, in_channels=in_channels)\n",
        "trained = train(model, bundle, cfg_base, device=cfg_base.device, verbose=True, return_history=False)\n",
        "\n",
        "clip = bundle.meta.get('clip', (0.0, 1.0))\n",
        "X_adv_val = generate_adversarial(trained, bundle.X_val, bundle.y_val, cfg_base, clip=clip)\n",
        "X_adv_test = generate_adversarial(trained, bundle.X_test, bundle.y_test, cfg_base, clip=clip)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visual sanity check: clean vs adversarial images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2YAAAEuCAYAAADlQQHWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa2ElEQVR4nO3dCYwedfkH8HmhFFxUUPFYRLFVENSoFDzwSD04VBRFixo14BXAu4gaigcohKJ4oSaKmGBQoqIxeATRGAsWBcTWC0zFAzDCautBteAB9P3nmWT3v7vd8k63s/PMvPv5JAR4O535zW+OzHd+M/P0+v1+vwAAACDNDnmLBgAAIAhmAAAAyQQzAACAZIIZAABAMsEMAAAgmWAGAACQTDADAABIJpgBAAAkE8wAAACSCWbz3GWXXVb0er3y3wBd9/nPf748p914443ZTYF57WEPe1hx2mmnVZ721a9+9ayWE8d71eVs67VR1fPIpk2bigc84AHFhRdeWMxX07fhpZdeWtzznvcsNmzYkNqurhHMAAAYCj/+8Y/LoHbrrbc2tsxzzjmnuNe97lW8/OUvb2yZbfec5zyneMQjHlGsXLkyuymdIpgBADA0wez9739/Y8HsjjvuKIPZ61//+mLHHXdsZJldcfzxxxfnnntu8a9//Su7KZ0hmAEAwCx8+9vfLh/Xe+lLX9r4sjdv3lz85z//KdrqJS95SfHf//63+OpXv5rdlM4QzOaBm2++uXjd615X7LnnnsXOO+9cLFq0qHjDG95Q/O9//9vq37n66qvLYejddtutGBkZKZYuXVr86Ec/mjLNTTfdVLzxjW8sHvnIRxb3uMc9ivvd737F0UcfvcUz2ePvfMTff/vb317c//73L3bdddfiqKOO8uwxMKvzSrjuuuuKZz3rWeV0e+21V3HGGWeUFyqTPf/5zy8WL14847IOPvjg4qCDDpqzdQGm6vf75XEax2tcWzzzmc8sj+OZxIjX8uXLi4c85CHltUs8FvfBD35wi2N8sniE8Z3vfGf533GtE9cek98VO//888tzRrwPFvN81KMeVXz605/ernW6+OKLy/erHv7wh0/5Pd63ines4hrsRS96Ufnfcf3zjne8o7jrrrumTHvbbbcVJ5100sS6xvnvwx/+cNlfk8W6vPnNby7fZXv0ox9dThvvco1fZ11xxRXFW9/61nI5u+++ezliFdd60ZfHHHNMcZ/73Kf8513vetcW845+/fjHP17Od5dddike+MAHln//H//4x6y3YfTzYx/72OIb3/jGdvXxfLIguwHMrVtuuaV44hOfWB6Uxx13XLHffvuVJ4mvfe1rxe233z7j3/nBD35QPPe5zy0OPPDA4tRTTy122GGHiZPZ6tWry/mFa665pnxkIJ6pjgM0TnxxgnvGM55R/PrXvy4P2Mne8pa3lCeEmGdMGyeAOMF85StfaaQvgParel7585//XF4Q3HnnncXJJ59c3uz57Gc/W4a0yV72speVFyQx3yc84QlTAuBVV11VnH322Y2vI8xX73vf+8qL+uc973nlP2vXri0OO+ywLW4Ux/VJ3BCO65UIBw996EPL88KKFSuKsbGx8vphJi9+8YuL66+/vvjSl75UfOxjHyv22GOP8vcIKiHOJRE8jjzyyGLBggXFt771rfJGUISSN73pTbNap2jXkiVLZvyzCGCHH3548aQnPakMWt///veLj3zkI2WIixvk40En2rNq1aryJvrjH//44rvf/W4ZMGP9Yz2mX6NddNFF5fVTrF+Ewp///OcT11kPetCDykc54/wW58QIaNHG6MMzzzyzuOSSS8rz3mMe85jy3Dgu+jkC3mte85oy3N1www3Fpz71qeJnP/tZeWN9p5122qZtOC6uJSO8UlGfoXbMMcf0d9hhh/4111yzxZ9t3ry5v2rVqrhlUv57/Ld99tmnf/jhh5f/Pe7222/vL1q0qH/ooYdO+W26K6+8spzfBRdcMPHb+eefX/52yCGHTJnniSee2N9xxx37t956a63rDHRX1fPK8uXLy9+uvvrqid/Wr1/f32233crfb7jhhvK3jRs39nfeeef+SSedNGWeH/rQh/q9Xq9/0003zen6wHy1995790899dQpx+fChQv7RxxxxJRrgVNOOaU8Zo899tiJ304//fT+rrvu2r/++uunzPPkk08urxv++Mc/TvwWf3fycs4+++wp54BB55e43lm8ePGU38avjWaax2R33HFHeR6Zfn4JsT4xjw984ANTfj/ggAP6Bx544MT/X3zxxeV0Z5xxxpTpli1bVs77d7/73ZR1jWu66667bsq049dZ06/dDj744HIeJ5xwwsRvd955Z3+vvfbqL126dOK31atXl3//wgsvnDLfSy+9dMrv27INx5155pnln/3lL3/Zaj/y/zzKOMTiDlDcpXjBC14w4+M6Mew9Xdx1+e1vf1u84hWvKP72t78Vf/3rX8t/Ypj92c9+dvHDH/5w4jGCyXem4+XXmD4eNYi7M3EHZboYsZu8zKc//enl3aS4cw2wLeeVuOv75Cc/eWIEf/yu+Ctf+cop87v3ve9dPgEQd5gnP7oTI/Xx9+MuMjD3YrQoRlViVGfytUA8rjhdvJMU1wjxlM34dUj8c8ghh5TXDXEtsr3nl40bN5bzjJG5P/zhD+X/b6u///3v5Xkl2rk1J5xwwpT/j/WK5U0+l8VHQ2KUarJ4tDHm/Z3vfGfK79HeeARzJjHiNrlvY6Qu5hG/j4tlxTXh5DZEf8erK4ceeuiU/o7RrngEM0bztnUbjhvvm5gfg3mUcYjF+1v//Oc/y+HqqiKUhWOPPXar08TJKw60f//73+VnUOMxxxhun3zRM9MJbvoF0PjBOv35ZWD+qnpeiRs6cdExXbybMV08zhg3qa688sriKU95SvH73/++WLNmzVYfhwLqN34Tdp999pnye9xQmR5s4lrkl7/85cQjiNOtX79+Vm2IR/LidYo4F0x/nSPOLxFOZmP6+1rj4l2t6esQ6zr5uif6Jb4BEJ/bn2z//fef+PPJ4t25rZl+nTW+PvHu2vTfJ7ch+jvWP94Ju7v+3pZtOL1vZhoMYEuCGVOMj4bF88fxnPNM4u5JiDsmcfEUd0riJfo40OPAi3dDZno5d2ufkd3aCQ2Yf7b1vFJFPDUQ76bFqFkEs/h3vDsbHxUB2ieO9Ri9iY9UzGTffffd5nnGDZl48ifetf/oRz9ahpWFCxeWI1bxHtdszi/3ve99y/PT1m4wz8Xn86e/R1tleTP9PvnaK9b97gpkby0gVzHeN+Pv+3H3BLMhFgdSPMZz7bXXVv47418Vir8XjwzcnfiASIysxYus4+KzrU0WdQSGS9Xzyt577z0xwj/Zb37zmy1+iw+DxNcZ43GduCCLxxjjcaK4Sw00I47ZEMft5C+lxtM904NNXIts2rRp4HXITLY2MhMf+ohPt3/zm9+cMrI0/pjebMQHRKKt8aGM7emXeEQwan1NHjVbt27dxJ/PtViHaMNTn/rUuw1+27INx0XfRCjbnnA3n3jHbIjFHeH4RGucjH76059WGqmK54njAI2vB8VJcbrJn7ePOzDT5/HJT35yi8/AAlRV9bwSXwOLr4795Cc/mXJ+2tod33icMb5S+7nPfa74xS9+Uf4/0JwIWfFlvzieJx/jMz1SHDXB4nHD+DrhdHGTJr7GujVxI2Z8uplGjaY/Hh0j9NsjRvZnusaqKs5lcX6LLyBOFqN4ETLjHdm5Fv0dbTj99NO3+LPo6/G+3JZtOC4eG48+ohojZkMuPo36ve99r3xZND6+Ec8sx6dm485x1LuYKczFhUucCOKTsvHZ1Ac/+MHlux5xVylG0iLohbgD/YUvfKF81CheRI2TaNxxibpDALNR9bwSjzjFdFFv8W1ve9vE5/Ljjm68mzLTxU/cjY4aQnGBFoVPgeaM1/CKd0jjOI9jMj7FHh+3mP6YW3wqPka2YrqoBxY3jeMjZL/61a/KUfUoo7G1R+Ni2vDud7+7fAQ6gkQ8zhyfdI9HF+O/49PwcfP5vPPOKx/hi+ui2XrhC19YnoviM/2zecQy2hOlP6K9sV6Pe9zjyuu2qP0Vj3RPr482F+IaMfoktk18BC76KvotRsbievGcc84pli1btk3bcPzdtDgfz7YUwXwkmA25CFVRLPq9731veSc5PgYSv0Xwml5nbFzUC4qLobhzEndw4uQVdTHiRfs4cMfFgRoXODHfeNQohsDjAipqdgDMRtXzyujoaHmzKN5JO+uss8rgFl8/i8cTJ3+BbPJL+FErKOYbd3239pI7MHei/lUci5/5zGfK4zeuKyKEHHHEEVOmi+uTyy+/vLy5HMHgggsuKG8MR/CJGl1395GOqFcY1y+xjCi+HO9PxeN08WGgCHXvec97ynAR1zVRSyzCxmtf+9pZr1MEqwgl8e5qzHtbxQ3xCKFRHywes44RvKhNFu/6x5cZmxL9FaH23HPPLU455ZTyMc1ox6te9aryPLyt2zB8/etfL4tgx4gc1fTim/kVpwUAgIHioj5Gu0477bSiay677LJyFCsCXazHIBEEI1DFCNNcfPCjqw444IDyZv/0ItlsnXfMAABglk488cTy6aIvf/nL2U1pjRitjKC6YsWK7KZ0ikcZAQBglqKM0Gxrqw2reP93po/IcfeMmAEAACTzjhkAAEAyI2YAAADJBDMAAICufPwjqo8DjGvLU9BVzk1R84r6bE8x1rnS1m1cV1+1df3q6oOq61dlXl06N7WlrcOijdeqbd3GdfVVW9ev6WO0rnkZMQMAAEgmmAEAACQTzAAAAJIJZgAAAMkEMwAAgGSCGQAAQDLBDAAAIJlgBgAA0JUC0wBtVKUwbdUiv3UV8a1zeXUW561LG4sdt7XP69w/69LGfaqqtrZrtsVkqxb5rauIb53La2MB7TYWO25rn9e5f9al18J9qqq62mXEDAAAIJlgBgAAkEwwAwAASCaYAQAAJBPMAAAAkglmAAAAyQQzAACAZIIZAABAMsEMAAAgWa9fsVR109W/gXarq8r99qpybhodHa00r7GxsVrmVWU+29Iuitr6vArbpbq6jpk6l9elc1PVttY1r6rXcm3pw2FQ5/Wz7ZJz/DW5PCNmAAAAyQQzAACAZIIZAABAMsEMAAAgmWAGAACQTDADAABIJpgBAAAkE8wAAACSLchuAMD2qLN4bZ3Fo7tawLeKLhfQrmsbt3Hd6tTlbdwWdRavrbN4dFcL+FbR5QLadW3jNq5bnXod3sZVGDEDAABIJpgBAAAkE8wAAACSCWYAAADJBDMAAIBkghkAAEAywQwAACCZYAYAAJCs169Yga3pwoU072lPe9rAaVavXl1pXvvvv//AadatW1dpXrRTW4o3Vjk3KYJbXZ3Flesqxn300UcPnOaiiy6qNK/dd9994DQjIyNFV7WxOHbT+1SXzk1taWsX1NmfdV3T1ln4e9j3hTYeD72G96kq8zJiBgAAkEwwAwAASCaYAQAAJBPMAAAAkglmAAAAyQQzAACAZIIZAABAMsEMAAAgmWAGAACQbEF2A+iWzZs3ZzcBphgdHc1uwlCpsz/buG2WLFkycJp169YVXVVXn4+NjdW2vGHfp7am3+9nN2Go1NmfTW6bPfbYo7FltVldfd7r9WpbXhv3KSNmAAAAyQQzAACAZIIZAABAMsEMAAAgmWAGAACQTDADAABIJpgBAAAkE8wAAACSKTANwJyoWqS4SWvXrh04zcjISDHfdamQM8xVkeJBFBFvXn/I+9yIGQAAQDLBDAAAIJlgBgAAkEwwAwAASCaYAQAAJBPMAAAAkglmAAAAyQQzAACAZApMMycWLVo0cJp169Y10haoWui4rqK6dS6vyrzaWgy4je1atmzZwGkuueSS1u1TderyPtXGouVNFDquq6huncurMq+2FgNua7u6uE/VqdfhfaquthsxAwAASCaYAQAAJBPMAAAAkglmAAAAyQQzAACAZIIZAABAMsEMAAAgmWAGAACQTDADAABItiC7AQyn2267LbsJMGF0dLTSdGNjY7XMq+ryqGbNmjW1zevyyy+vZT5d3sZNt72u42pbpuuKfr9fabper1fLvKouj+7q8jbuN9z2uo6rbZluECNmAAAAyQQzAACAZIIZAABAMsEMAAAgmWAGAACQTDADAABIJpgBAAAkE8wAAACSKTDNnFi/fn12E2BeFd7tqip9sHjx4tqWt2HDhoHTjIyM1LY8hn8fbkKXC+92lT4Yfv0Wbj8jZgAAAMkEMwAAgGSCGQAAQDLBDAAAIJlgBgAAkEwwAwAASCaYAQAAJBPMAAAAkikwzYTly5dnNwHmTdHkqoV36yxC3dWC1l/84hdrm9eSJUsGTrNq1apO9hPUUTS5auHdOgswK+ZcjX4afkbMAAAAkglmAAAAyQQzAACAZIIZAABAMsEMAAAgmWAGAACQTDADAABIJpgBAAAkE8wAAACSLchuAO2x0047ZTcBhsLo6OjQz6vJNjV9bqrSprGxsUbn1fS2q3P9aI9+vz/085rvber1eo3Oq+l+6tW4fm1kxAwAACCZYAYAAJBMMAMAAEgmmAEAACQTzAAAAJIJZgAAAMkEMwAAgGSCGQAAQDIFpgFqLvTb5eK8TRc7rtpXdVm7du3AaTZu3Fg0qY37QdPbuI190CZ1FfrtcnHeposdd7m4cl3auB/0h3wbGzEDAABIJpgBAAAkE8wAAACSCWYAAADJBDMAAIBkghkAAEAywQwAACCZYAYAAJBMgWmAFhe5bbo4b9N90MY+b2Ob6izE3eVt3HRB8rZoY6HfpovzNt0HbezzNrapzqLX/Q5v47qOByNmAAAAyQQzAACAZIIZAABAMsEMAAAgmWAGAACQTDADAABIJpgBAAAkE8wAAACSKTANULOmCz5XLbo77IWTq1iyZMnAadatW9e6Pm/jtquzAPp8LRzdtKYLPlctPtzVwsldbXedbW9jH9S5/eosoF2FETMAAIBkghkAAEAywQwAACCZYAYAAJBMMAMAAEgmmAEAACQTzAAAAJIJZgAAAMkEMwAAgGQLshsA0BZjY2MDpxkdHa1lPlXnVed86lq/pq1Zs2bgNAcddFClea1du3bgNCMjI53sp6rq3A+a3ofnq16vN3Cafr9fy3yqzqvO+dS1fnS7n3o17gdN78N1MWIGAACQTDADAABIJpgBAAAkE8wAAACSCWYAAADJBDMAAIBkghkAAEAywQwAACCZAtPzxL777jtwmsMOO6yRtkBbDXux3LqKY9e5fkuXLh04zfHHH1/b8pYsWTJwmnXr1tW2vGFXtZh6k0XSh1FXi+VWVVdx7DrXr8q8jjrqqNqWR72qFlNvW5F0I2YAAADJBDMAAIBkghkAAEAywQwAACCZYAYAAJBMMAMAAEgmmAEAACQTzAAAAJIpMD1PLFgweFMvXLiwkbZAW9VVXLlqEdw2Fnxuujh2lXNTndauXTtwmpGRkaJJXd7GTe8vbS3ePtfqKl5btehuVws+N+2KK64ohlmXt3G/4f2lruUZMQMAAEgmmAEAACQTzAAAAJIJZgAAAMkEMwAAgGSCGQAAQDLBDAAAIJlgBgAAkEwwAwAASLYguwEA22NsbGzgNKOjo5XmVXW6puZT97zq6qsq86k6rzVr1hRNWrJkycBpVq1a1dltPOyq7ntt0Ov1Bk7T7/crzavqdE3Np+551dVXVeZTdV7Dvk8Ncz91edsYMQMAAEgmmAEAACQTzAAAAJIJZgAAAMkEMwAAgGSCGQAAQDLBDAAAIJlgBgAAkEyB6XniyCOPzG4CzAnFedvbV1WKAX/iE58omrR27dpO7lN1FvVuo2FcP8V529tXTRdqrksb26Sod73rZ8QMAAAgmWAGAACQTDADAABIJpgBAAAkE8wAAACSCWYAAADJBDMAAIBkghkAAEAyBabnif3226+W+Vx11VWVpvvTn/5Uy/JgvqtSeLdq0d265lVnkd+6zk033nhjpek2btw4cJqRkZHWFUTuUmHluVS13+lWkea65tXGIsYbNmyoNN2KFSsGTrNy5crWFURuY59nqGsfNmIGAACQTDADAABIJpgBAAAkE8wAAACSCWYAAADJBDMAAIBkghkAAEAywQwAACCZYAYAAJBsQXYD6JaqFew3bdo0522BMDY2NnCa0dHRxudV1/LqVGfb27Z+Vc9Nw96XVdrV9H5eRdPLa0Kv1xs4Tb/fb3xedS2vTnW2vY39WcVZZ501cJqVK1d2si+rtqvXwu3S9PKMmAEAACQTzAAAAJIJZgAAAMkEMwAAgGSCGQAAQDLBDAAAIJlgBgAAkEwwAwAASKbANNvkvPPOy24CzFlh2mEvqtvGwsJ1Oe6444a6z7u6XYZ9v2uqMO2wF9VtY2HhpnW1z7u8XXot3O+MmAEAACQTzAAAAJIJZgAAAMkEMwAAgGSCGQAAQDLBDAAAIJlgBgAAkEwwAwAASKbANBNuvvnmgdNce+21jbQFuqxKQd2qRXW7XJy3rnbdddddA6fZZZddimHug6r7VFcLqdd5zLB9BXWrFtVtY3Hequpq14YNG4quqqsPqu5TXS2k3qvxmKnCiBkAAEAywQwAACCZYAYAAJBMMAMAAEgmmAEAACQTzAAAAJIJZgAAAMkEMwAAgGSCGQAAQLJev2Kp6jorewPdV1eV++2155571javsbGxgdOMjo4WXVVl/aqosw/a2KamDft+1+R+0KZzU52qXIN1eb3rusassw/a2KamDft+13T+qdJXRswAAACSCWYAAADJBDMAAIBkghkAAEAywQwAACCZYAYAAJBMMAMAAEgmmAEAACRTYBqYlWEsMN10sdxhLxrcxuLKdRYyrsI2bt4tt9yS3YTWqnot15bz+3wqrtz0dbZt3E5GzAAAAJIJZgAAAMkEMwAAgGSCGQAAQDLBDAAAIJlgBgAAkEwwAwAASCaYAQAAJFuQ3QCALhUo7nJR4Tb2VdOGff3aaL7ud00XKO5yUeE29lXThn392qjXwv3OiBkAAEAywQwAACCZYAYAAJBMMAMAAEgmmAEAACQTzAAAAJIJZgAAAMkEMwAAgGSCGQAAQLIF2Q0A2B6jo6MDpxkbG6ttXnWq0q6m29S0YV+/rqrzmJmv27jf7w+cptfr1TavOlVpV9Ntatqwr19X9Wo8Ztq4jY2YAQAAJBPMAAAAkglmAAAAyQQzAACAZIIZAABAMsEMAAAgmWAGAACQTDADAABI1uu3sboaAADAPGLEDAAAIJlgBgAAkEwwAwAASCaYAQAAJBPMAAAAkglmAAAAyQQzAACAZIIZAABAMsEMAACgyPV/5ZMVs9ChpVoAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 900x300 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def _show(img, ax, title=''):\n",
        "    x = np.asarray(img)\n",
        "    # MNIST is (C,H,W) with C=1\n",
        "    if x.ndim == 3 and x.shape[0] in {1,3}:\n",
        "        x2 = np.transpose(x, (1,2,0))\n",
        "        if x2.shape[2] == 1:\n",
        "            x2 = x2[:,:,0]\n",
        "    else:\n",
        "        x2 = x\n",
        "    ax.imshow(x2, cmap='gray')\n",
        "    ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "\n",
        "i = 0\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
        "_show(bundle.X_test[i], axes[0], 'clean')\n",
        "_show(X_adv_test[i], axes[1], 'adv')\n",
        "delta = np.abs(X_adv_test[i] - bundle.X_test[i])\n",
        "_show(delta / (delta.max() + 1e-12), axes[2], '|delta| (normed)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subsample points for PH scoring (runtime control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val used: (150, 1, 28, 28) (150, 1, 28, 28)\n",
            "Test used: (200, 1, 28, 28) (200, 1, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "def _subsample(X, y, n_max: int):\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y, dtype=int)\n",
        "    if len(X) <= n_max:\n",
        "        return X, y\n",
        "    idx = rng.choice(np.arange(len(X)), size=int(n_max), replace=False)\n",
        "    return X[idx], y[idx]\n",
        "\n",
        "X_val_clean_used, y_val_clean_used = _subsample(bundle.X_val, bundle.y_val, MAX_POINTS_FOR_SCORING)\n",
        "X_val_adv_used, y_val_adv_used = _subsample(X_adv_val, bundle.y_val, MAX_POINTS_FOR_SCORING)\n",
        "X_test_clean_used, y_test_clean_used = _subsample(bundle.X_test, bundle.y_test, MAX_POINTS_FOR_SCORING)\n",
        "X_test_adv_used, y_test_adv_used = _subsample(X_adv_test, bundle.y_test, MAX_POINTS_FOR_SCORING)\n",
        "\n",
        "print('Val used:', X_val_clean_used.shape, X_val_adv_used.shape)\n",
        "print('Test used:', X_test_clean_used.shape, X_test_adv_used.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _needs_y_pred(det_cfg: DetectorConfig) -> bool:\n",
        "    if not bool(getattr(det_cfg, 'topo_class_conditional', False)):\n",
        "        return False\n",
        "    m = str(getattr(det_cfg, 'topo_class_scoring_mode', 'min_over_classes')).strip().lower()\n",
        "    return m in {'predicted_class', 'pred', 'contrastive_pred_gap', 'contrastive', 'pred_gap'}\n",
        "\n",
        "\n",
        "def run_variant(*, name: str, cfg: ExperimentConfig):\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    scores_val_clean = compute_scores(X_val_clean_used, trained, bundle=bundle, cfg=cfg)\n",
        "    scores_val_adv = compute_scores(X_val_adv_used, trained, bundle=bundle, cfg=cfg)\n",
        "    scores_test_clean = compute_scores(X_test_clean_used, trained, bundle=bundle, cfg=cfg)\n",
        "    scores_test_adv = compute_scores(X_test_adv_used, trained, bundle=bundle, cfg=cfg)\n",
        "\n",
        "    scores_val_all = concat_scores(scores_val_clean, scores_val_adv)\n",
        "    any_key = next(iter(scores_val_all.keys()))\n",
        "    labels_val = np.concatenate([\n",
        "        np.zeros(len(scores_val_clean[any_key]), dtype=int),\n",
        "        np.ones(len(scores_val_adv[any_key]), dtype=int)\n",
        "    ])\n",
        "    y_val_all = np.concatenate([np.asarray(y_val_clean_used, dtype=int), np.asarray(y_val_adv_used, dtype=int)])\n",
        "\n",
        "    y_pred_val_all = None\n",
        "    if _needs_y_pred(cfg.detector):\n",
        "        y_pred_val_clean = get_model_predictions(trained, np.asarray(X_val_clean_used), device=str(cfg.device), return_probs=False)\n",
        "        y_pred_val_adv = get_model_predictions(trained, np.asarray(X_val_adv_used), device=str(cfg.device), return_probs=False)\n",
        "        y_pred_val_all = np.concatenate([np.asarray(y_pred_val_clean, dtype=int), np.asarray(y_pred_val_adv, dtype=int)])\n",
        "\n",
        "    detector = fit_detector(scores_val_all, labels_val, cfg, y_true=y_val_all, y_pred=y_pred_val_all)\n",
        "\n",
        "    scores_test_all = concat_scores(scores_test_clean, scores_test_adv)\n",
        "    any_key_t = next(iter(scores_test_all.keys()))\n",
        "    labels_test = np.concatenate([\n",
        "        np.zeros(len(scores_test_clean[any_key_t]), dtype=int),\n",
        "        np.ones(len(scores_test_adv[any_key_t]), dtype=int)\n",
        "    ])\n",
        "\n",
        "    y_pred_test_all = None\n",
        "    if _needs_y_pred(cfg.detector):\n",
        "        y_pred_test_clean = get_model_predictions(trained, np.asarray(X_test_clean_used), device=str(cfg.device), return_probs=False)\n",
        "        y_pred_test_adv = get_model_predictions(trained, np.asarray(X_test_adv_used), device=str(cfg.device), return_probs=False)\n",
        "        y_pred_test_all = np.concatenate([np.asarray(y_pred_test_clean, dtype=int), np.asarray(y_pred_test_adv, dtype=int)])\n",
        "\n",
        "    try:\n",
        "        raw_scores_test = detector.score(scores_test_all, y_pred=y_pred_test_all)\n",
        "    except TypeError:\n",
        "        raw_scores_test = detector.score(scores_test_all)\n",
        "\n",
        "    thr = float(getattr(detector, 'threshold', np.nan))\n",
        "    metrics = evaluate_detector(np.asarray(labels_test, dtype=int), np.asarray(raw_scores_test, dtype=float), threshold=thr)\n",
        "    wall = time.perf_counter() - t0\n",
        "\n",
        "    return {\n",
        "        'name': str(name),\n",
        "        'cfg': cfg,\n",
        "        'detector': detector,\n",
        "        'scores_test_all': scores_test_all,\n",
        "        'labels_test': labels_test,\n",
        "        'raw_scores_test': np.asarray(raw_scores_test, dtype=float),\n",
        "        'threshold': thr,\n",
        "        'metrics': metrics,\n",
        "        'wall_s': float(wall),\n",
        "        'y_pred_test_all': y_pred_test_all,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variants + run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running V0_pooled_global\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, cfg \u001b[38;5;129;01min\u001b[39;00m variants:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning\u001b[39m\u001b[38;5;124m'\u001b[39m, name)\n\u001b[0;32m---> 20\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mrun_variant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m     22\u001b[0m     m \u001b[38;5;241m=\u001b[39m r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "Cell \u001b[0;32mIn[12], line 13\u001b[0m, in \u001b[0;36mrun_variant\u001b[0;34m(name, cfg)\u001b[0m\n\u001b[1;32m     11\u001b[0m scores_val_clean \u001b[38;5;241m=\u001b[39m compute_scores(X_val_clean_used, trained, bundle\u001b[38;5;241m=\u001b[39mbundle, cfg\u001b[38;5;241m=\u001b[39mcfg)\n\u001b[1;32m     12\u001b[0m scores_val_adv \u001b[38;5;241m=\u001b[39m compute_scores(X_val_adv_used, trained, bundle\u001b[38;5;241m=\u001b[39mbundle, cfg\u001b[38;5;241m=\u001b[39mcfg)\n\u001b[0;32m---> 13\u001b[0m scores_test_clean \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_clean_used\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbundle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m scores_test_adv \u001b[38;5;241m=\u001b[39m compute_scores(X_test_adv_used, trained, bundle\u001b[38;5;241m=\u001b[39mbundle, cfg\u001b[38;5;241m=\u001b[39mcfg)\n\u001b[1;32m     16\u001b[0m scores_val_all \u001b[38;5;241m=\u001b[39m concat_scores(scores_val_clean, scores_val_adv)\n",
            "File \u001b[0;32m~/Desktop/project/topology-and-robustness-in-DNNs/src/api.py:449\u001b[0m, in \u001b[0;36mcompute_scores\u001b[0;34m(X_points, model, bundle, cfg)\u001b[0m\n\u001b[1;32m    446\u001b[0m probs_train \u001b[38;5;241m=\u001b[39m _softmax_probs(logits_train)\n\u001b[1;32m    447\u001b[0m f_train \u001b[38;5;241m=\u001b[39m _scalar_f_from_probs(probs_train)\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_graph_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_points\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mZ_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbundle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/project/topology-and-robustness-in-DNNs/src/graph_scoring.py:579\u001b[0m, in \u001b[0;36mcompute_graph_scores\u001b[0;34m(X_points, model, Z_train, f_train, graph_params, device, y_train, y_points)\u001b[0m\n\u001b[1;32m    577\u001b[0m cloud \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([Z_points[i]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), neigh])\n\u001b[1;32m    578\u001b[0m cloud \u001b[38;5;241m=\u001b[39m _normalize_cloud(cloud, dists\u001b[38;5;241m=\u001b[39mdists_max[:kk])\n\u001b[0;32m--> 579\u001b[0m feats_k \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_persistence_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopo_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix_keys:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;66;03m# Prefix keys so they remain `topo_*` and distinct per k.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m feats_k\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;66;03m# key is like \"topo_h0_count\" -> \"topo_k30_h0_count\"\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/project/topology-and-robustness-in-DNNs/src/topology_features.py:143\u001b[0m, in \u001b[0;36mlocal_persistence_features\u001b[0;34m(point_cloud, topo_cfg, return_diagrams)\u001b[0m\n\u001b[1;32m    141\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(topo_cfg\u001b[38;5;241m.\u001b[39mpca_dim)), r_max))\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;241m<\u001b[39m d:\n\u001b[0;32m--> 143\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mPCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     point_cloud \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# ripser's Cython backend expects thresh to be a real number; passing None can error.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# If thresh is unset, omit it (ripser will use its internal default).\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/project/topology-and-robustness-in-DNNs/venv/lib/python3.9/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
            "File \u001b[0;32m~/Desktop/project/topology-and-robustness-in-DNNs/venv/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/project/topology-and-robustness-in-DNNs/venv/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:468\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
            "File \u001b[0;32m~/Desktop/project/topology-and-robustness-in-DNNs/venv/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:542\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovariance_eigh\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_array_api_compliant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, xp)\n",
            "File \u001b[0;32m~/Desktop/project/topology-and-robustness-in-DNNs/venv/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:583\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components, xp, is_array_api_compliant)\u001b[0m\n\u001b[1;32m    573\u001b[0m x_is_centered \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_api_compliant:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# Use scipy.linalg with NumPy/SciPy inputs for the sake of not\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;66;03m# introducing unanticipated behavior changes. In the long run we\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;66;03m# solver by default though (assuming both are built against the\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;66;03m# same BLAS).\u001b[39;00m\n\u001b[0;32m--> 583\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_centered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(X_centered, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/Desktop/project/topology-and-robustness-in-DNNs/venv/lib/python3.9/site-packages/scipy/linalg/_decomp_svd.py:141\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    137\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    138\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m \u001b[43mgesXd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_uv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "variants = []\n",
        "cfg_v0 = cfg_base\n",
        "variants.append(('V0_pooled_global', cfg_v0))\n",
        "\n",
        "cfg_v1 = replace(cfg_base, detector=replace(cfg_base.detector, topo_class_conditional=True, topo_class_scoring_mode='min_over_classes'))\n",
        "variants.append(('V1_classcond_global', cfg_v1))\n",
        "\n",
        "cfg_v2 = replace(cfg_v1, graph=replace(cfg_v1.graph, topo_neighbor_mode='class_pred'))\n",
        "variants.append(('V2_classcond_classPredNbr', cfg_v2))\n",
        "\n",
        "cfg_v3 = replace(cfg_v2, graph=replace(cfg_v2.graph, topo_metric_normalization='whiten', topo_whiten_ridge=1e-3))\n",
        "variants.append(('V3_classPredNbr_whiten', cfg_v3))\n",
        "\n",
        "cfg_v4 = replace(cfg_v3, detector=replace(cfg_v3.detector, topo_class_scoring_mode='contrastive_pred_gap'))\n",
        "variants.append(('V4_contrastive_gap', cfg_v4))\n",
        "\n",
        "results = []\n",
        "for name, cfg in variants:\n",
        "    print('Running', name)\n",
        "    r = run_variant(name=name, cfg=cfg)\n",
        "    results.append(r)\n",
        "    m = r['metrics']\n",
        "    print('  roc_auc=', m.get('roc_auc'), 'pr_auc=', m.get('pr_auc'), 'fpr@95=', m.get('fpr_at_tpr95'), 'wall_s=', r['wall_s'])\n",
        "\n",
        "[(r['name'], float(r['metrics']['roc_auc'])) for r in results]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROC curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "for r in results:\n",
        "    fpr = np.asarray(r['metrics']['fpr'])\n",
        "    tpr = np.asarray(r['metrics']['tpr'])\n",
        "    auc = float(r['metrics']['roc_auc'])\n",
        "    plt.plot(fpr, tpr, label=f\"{r['name']} (AUC={auc:.3f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], '--', color='gray', linewidth=1)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curves (IMAGE: clean vs adversarial)')\n",
        "plt.legend(fontsize=8)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Score distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ncols = 2\n",
        "nrows = int(np.ceil(len(results) / ncols))\n",
        "fig, axes = plt.subplots(nrows, ncols, figsize=(10, 4*nrows), squeeze=False)\n",
        "\n",
        "for ax, r in zip(axes.ravel(), results):\n",
        "    y = np.asarray(r['labels_test'], dtype=int)\n",
        "    s = np.asarray(r['raw_scores_test'], dtype=float)\n",
        "    thr = float(r['threshold'])\n",
        "    ax.hist(s[y == 0], bins=40, alpha=0.6, label='clean', density=True)\n",
        "    ax.hist(s[y == 1], bins=40, alpha=0.6, label='adv', density=True)\n",
        "    ax.axvline(thr, color='k', linestyle='--', linewidth=1)\n",
        "    ax.set_title(f\"{r['name']}\\nAUC={float(r['metrics']['roc_auc']):.3f}\")\n",
        "    ax.set_xlabel('detector score')\n",
        "    ax.set_ylabel('density')\n",
        "    ax.legend(fontsize=8)\n",
        "    ax.grid(True, alpha=0.2)\n",
        "\n",
        "for ax in axes.ravel()[len(results):]:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
